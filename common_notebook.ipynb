{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f070758d",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 onepoint and contributors\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b99b16",
   "metadata": {},
   "source": [
    "# Common methods and constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e932d4f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74d08bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import io\n",
    "import smote_variants as sv\n",
    "import logging\n",
    "from enum import Enum\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e1a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = 999\n",
    "logging.getLogger(sv.__name__).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec31893",
   "metadata": {},
   "source": [
    "## Data constants and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b3c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_COLUMNS = ['projectname', 'packageandclass', 'path',\n",
    "                  'readable very high', 'readable high', 'readable low', 'readable very low',\n",
    "                  'understandable very high', 'understandable high', 'understandable low', 'understandable very low',\n",
    "                  'complex very high', 'complex high', 'complex low', 'complex very low',\n",
    "                  'not modular very high', 'not modular high', 'not modular low', 'not modular very low',\n",
    "                  'maintainable very high', 'maintainable high', 'maintainable low', 'maintainable very low']\n",
    "\n",
    "MAINTAINABILITY_COLUMNS = ['maintainable very high', 'maintainable high', 'maintainable low', 'maintainable very low']\n",
    "\n",
    "METRIC_COLUMNS_LOC = [\"nos\"]\n",
    "\n",
    "METRIC_COLUMNS_CGC = [\"cgc\"]\n",
    "\n",
    "METRIC_COLUMNS = [\"nos\", \"non\", \"non_m\", \"nos_m\",\n",
    "                  \"non_am\", \"nos_am\", \"non_lm\", \"nos_lm\",\n",
    "                  \"mll\", \"nos_deeper_4\",\n",
    "                  \"cbo\", \"cbod\", \"cboi\", \"cgc\", \"cyc\", \"dac\", \"dit\", \"lcom4\", \"lpc\",\n",
    "                  \"mnd\", \"mpc\", \"nlam\", \"nle\", \"noa\", \"noc\", \"nod\", \"noi\", \"noi_ic\",\n",
    "                  \"nolm\", \"nom\", \"nop\", \"rfc\", \"rfc_ic\"]\n",
    "\n",
    "METRICS_FILES = [\"aoi\", \"argouml\", \"diarymanagement-1\", \"diarymanagement-2\",\n",
    "                 \"diarymanagement-3\", \"jsweet-1\", \"jsweet-2\", \"jsweet-3\",\n",
    "                 \"jsweet-4\", \"junit4\"]\n",
    "\n",
    "SEEDS = [0, 13, 17, 33, 42, 89, 15837, 40325, 47137, 98035, 98225, 147904, 170800,\n",
    "         336695, 359004, 402483, 694957, 1606706, 2956982, 3180998, 109493891, 200929116,\n",
    "         721672933, 963307431, 1085070426, 1718898832, 3256195516, 3866174187, 4210241333, 4294967295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b34145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics():\n",
    "    metrics = []\n",
    "    for file in METRICS_FILES:\n",
    "        metrics.append(pd.read_csv(\"dataset/metrics/metrics_\" + file + \".csv\", delimiter=\";\", index_col=2))\n",
    "    metrics = pd.concat(metrics)\n",
    "    metrics = metrics.groupby(metrics.index).first()\n",
    "    return metrics\n",
    "\n",
    "def load_labels():\n",
    "    with open(\"dataset/maintainability_experts_labels/labels.csv\") as f:\n",
    "        content = f.read().replace(\"\\\"{\", \"\").replace(\"}\\\"\", \"\")\n",
    "    labels = pd.read_csv(\n",
    "        io.StringIO(content),\n",
    "        header=None,\n",
    "        skiprows=1,\n",
    "        names=LABELS_COLUMNS\n",
    "    )\n",
    "    labels.set_index(\"packageandclass\", inplace=True)\n",
    "    return labels\n",
    "\n",
    "def get_data():\n",
    "    labels_df = load_labels()\n",
    "    metrics_df = load_metrics()\n",
    "    return labels_df.join(metrics_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f94ded4",
   "metadata": {},
   "source": [
    "## Custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af896a80",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_estimator(name, parameters, seed):\n",
    "    \"\"\"Get a estimator instanciated with the given parameters.\"\"\"\n",
    "    \n",
    "    if name == 'ExtraTreesClassifier':\n",
    "        estimator = ExtraTreesClassifier(**parameters, random_state=seed)\n",
    "    elif name == 'ExtraTreesRegressor':\n",
    "        estimator = ExtraTreesRegressor(**parameters, random_state=seed)\n",
    "    elif name == 'KNeighborsClassifier':\n",
    "        estimator = KNeighborsClassifier(**parameters)\n",
    "    elif name == 'KNeighborsRegressor':\n",
    "        estimator = KNeighborsRegressor(**parameters)\n",
    "    elif name == 'GradientBoostingClassifier':\n",
    "        estimator = GradientBoostingClassifier(**parameters, random_state=seed)\n",
    "    elif name == 'GradientBoostingRegressor':\n",
    "        estimator = GradientBoostingRegressor(**parameters, random_state=seed)\n",
    "    elif name == 'RandomForestClassifier':\n",
    "        estimator = RandomForestClassifier(**parameters, random_state=seed)\n",
    "    elif name == 'RandomForestRegressor':\n",
    "        estimator = RandomForestRegressor(**parameters, random_state=seed)\n",
    "    elif name == 'AdaBoostClassifier':\n",
    "        estimator = AdaBoostClassifier(**parameters, random_state=seed)\n",
    "    elif name == 'AdaBoostRegressor':\n",
    "        estimator = AdaBoostRegressor(**parameters, random_state=seed)\n",
    "    elif name == 'LogisticRegression':\n",
    "        estimator = LogisticRegression(**parameters, random_state=seed)\n",
    "    elif name == 'BinaryDecompositionClassifier':\n",
    "        estimator = BinaryDecompositionClassifier(parameters, seed)\n",
    "    elif name == 'ChainedBinaryClassifier':\n",
    "        estimator = ChainedBinaryClassifier(parameters, seed)\n",
    "    elif name == 'ChainedBinaryInverseClassifier':\n",
    "        estimator = ChainedBinaryInverseClassifier(parameters, seed)\n",
    "    elif name == 'ChainedBinaryMedianClassifier':\n",
    "        estimator = ChainedBinaryMedianClassifier(parameters, seed)\n",
    "    elif name == 'IndividualProbabilitiesClassifier':\n",
    "        estimator = IndividualProbabilitiesClassifier(parameters, seed)\n",
    "    elif name == 'BinaryProbabilitiesClassifier':\n",
    "        estimator = BinaryProbabilitiesClassifier(parameters, seed)\n",
    "    elif name == 'RoundedRegressorClassifier':\n",
    "        estimator = RoundedRegressorClassifier(parameters, seed)\n",
    "    elif name == 'AlwaysAClassifier':\n",
    "        estimator = AlwaysAClassifier()\n",
    "    elif name == 'ClassBaselocClassifier':\n",
    "        estimator = ClassBaselocClassifier()\n",
    "    elif name == 'AlwaysTrueClassifier':\n",
    "        estimator = AlwaysTrueClassifier()\n",
    "    elif name == 'BinaryBaselocClassifier':\n",
    "        estimator = BinaryBaselocClassifier()\n",
    "    elif name == 'AlwaysMeanRegressor':\n",
    "        estimator = AlwaysMeanRegressor()\n",
    "    elif name == 'ContinuousBaselocRegressor':\n",
    "        estimator = ContinuousBaselocRegressor()\n",
    "    else: \n",
    "        raise ValueError(f\"{name} is not a supported estimator.\")\n",
    "        \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0274c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OversamplingClassifier(sv.classifiers.OversamplingClassifier):\n",
    "    \"\"\"OversamplingClassifier adding missing bindings.\"\"\"\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self.classifier_obj.decision_function(X)\n",
    "\n",
    "    classes_ = property(\n",
    "        lambda self: getattr(self.classifier_obj, 'classes_'),\n",
    "        lambda self, value: setattr(self.classifier_obj, 'classes_', value),\n",
    "        lambda self: delattr(self.classifier_obj, 'classes_')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0cb3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, by convention:\n",
    "# - maintainable very high -> 0\n",
    "# - maintainable high      -> 1\n",
    "# - maintainable low       -> 2\n",
    "# - maintainable very low  -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b23de4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDecompositionClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subclassifier=None, seed=None):\n",
    "        self.subclassifier = subclassifier\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subclassifier['estimator']\n",
    "        parameters = {k: self.subclassifier[k] for k in self.subclassifier if k != 'estimator'}\n",
    "        self.wtA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtC_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtA_.fit(X, y > 0)\n",
    "        self.wtB_.fit(X, y > 1)\n",
    "        self.wtC_.fit(X, y > 2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = self.wtA_.predict_proba(X)[:, 1]\n",
    "        wtB = self.wtB_.predict_proba(X)[:, 1]\n",
    "        wtC = self.wtC_.predict_proba(X)[:, 1]\n",
    "        pA = 1 - wtA\n",
    "        pB = wtA - wtB\n",
    "        pC = wtB - wtC\n",
    "        pD = wtC\n",
    "        proba = np.column_stack((pA, pB, pC, pD))\n",
    "        return proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e732fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedBinaryClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subclassifier=None, seed=None):\n",
    "        self.subclassifier = subclassifier\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subclassifier['estimator']\n",
    "        parameters = {k: self.subclassifier[k] for k in self.subclassifier if k != 'estimator'}\n",
    "        self.wtA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtC_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtA_.fit(X, y > 0)\n",
    "        self.wtB_.fit(X, y > 1)\n",
    "        self.wtC_.fit(X, y > 2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = self.wtA_.predict(X)\n",
    "        wtB = self.wtB_.predict(X)\n",
    "        wtC = self.wtC_.predict(X)\n",
    "        return np.where(wtA, np.where(wtB, np.where(wtC, 3, 2), 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1badebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedBinaryInverseClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subclassifier=None, seed=None):\n",
    "        self.subclassifier = subclassifier\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subclassifier['estimator']\n",
    "        parameters = {k: self.subclassifier[k] for k in self.subclassifier if k != 'estimator'}\n",
    "        self.wtA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtC_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtA_.fit(X, y > 0)\n",
    "        self.wtB_.fit(X, y > 1)\n",
    "        self.wtC_.fit(X, y > 2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = self.wtA_.predict(X)\n",
    "        wtB = self.wtB_.predict(X)\n",
    "        wtC = self.wtC_.predict(X)\n",
    "        return np.where(wtC, 3, np.where(wtB, 2, np.where(wtA, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da437766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainedBinaryMedianClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subclassifier=None, seed=None):\n",
    "        self.subclassifier = subclassifier\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subclassifier['estimator']\n",
    "        parameters = {k: self.subclassifier[k] for k in self.subclassifier if k != 'estimator'}\n",
    "        self.wtA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtC_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtA_.fit(X, y > 0)\n",
    "        self.wtB_.fit(X, y > 1)\n",
    "        self.wtC_.fit(X, y > 2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = self.wtA_.predict(X)\n",
    "        wtB = self.wtB_.predict(X)\n",
    "        wtC = self.wtC_.predict(X)\n",
    "        return np.where(wtB, np.where(wtC, 3, 2), np.where(wtA, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15e84e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualProbabilitiesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subregressor=None, seed=None):\n",
    "        self.subregressor = subregressor\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subregressor['estimator']\n",
    "        parameters = {k: self.subregressor[k] for k in self.subregressor if k != 'estimator'}\n",
    "        self.pA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.pB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.pC_ = get_estimator(name, parameters, self.seed)\n",
    "        self.pD_ = get_estimator(name, parameters, self.seed)\n",
    "        y_ = np.array(y.tolist())\n",
    "        self.pA_.fit(X, np.array(y_[:,0]))\n",
    "        self.pB_.fit(X, np.array(y_[:,1]))\n",
    "        self.pC_.fit(X, np.array(y_[:,2]))\n",
    "        self.pD_.fit(X, np.array(y_[:,3]))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pA = self.pA_.predict(X)\n",
    "        pB = self.pB_.predict(X)\n",
    "        pC = self.pC_.predict(X)\n",
    "        pD = self.pD_.predict(X)\n",
    "        proba = np.column_stack((pA, pB, pC, pD))\n",
    "        return proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d93f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryProbabilitiesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subregressor=None, seed=None):\n",
    "        self.subregressor = subregressor\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subregressor['estimator']\n",
    "        parameters = {k: self.subregressor[k] for k in self.subregressor if k != 'estimator'}\n",
    "        self.wtA_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtB_ = get_estimator(name, parameters, self.seed)\n",
    "        self.wtC_ = get_estimator(name, parameters, self.seed)\n",
    "        y_ = np.array(y.tolist())\n",
    "        self.wtA_.fit(X, np.array(y_[:,1]) + np.array(y_[:,2]) + np.array(y_[:,3]))\n",
    "        self.wtB_.fit(X, np.array(y_[:,2]) + np.array(y_[:,3]))\n",
    "        self.wtC_.fit(X, np.array(y_[:,3]))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = self.wtA_.predict(X)\n",
    "        wtB = self.wtB_.predict(X)\n",
    "        wtC = self.wtC_.predict(X)\n",
    "        pA = 1 - wtA\n",
    "        pB = wtA - wtB\n",
    "        pC = wtB - wtC\n",
    "        pD = wtC\n",
    "        proba = np.column_stack((pA, pB, pC, pD))\n",
    "        return proba.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac24b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundedRegressorClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, subregressor=None, seed=None):\n",
    "        self.subregressor = subregressor\n",
    "        self.seed = seed\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        name = self.subregressor['estimator']\n",
    "        parameters = {k: self.subregressor[k] for k in self.subregressor if k != 'estimator'}\n",
    "        self.regressor_ = get_estimator(name, parameters, self.seed)\n",
    "        self.regressor_.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = self.regressor_.predict(X)\n",
    "        return np.around(y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bb93be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlwaysTrueClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.array([False, True])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return len(X) * [True]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.array(len(X) * [[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5112c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryBaselocClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"This baseline classifier should only recieve nos metric as input.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cutoff = 275\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.array([False, True])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X[:,0] < self.cutoff\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y = self.predict(X)\n",
    "        p = np.where(y, 1, 0)\n",
    "        return np.column_stack((1 - p, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "372f4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlwaysAClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return len(X) * [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47abafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassBaselocClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"This baseline classifier should only recieve nos metric as input.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cutoff_a = 80\n",
    "        self.cutoff_b = 275\n",
    "        self.cutoff_c = 500\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = X[:,0] > self.cutoff_a\n",
    "        wtB = X[:,0] > self.cutoff_b\n",
    "        wtC = X[:,0] > self.cutoff_c\n",
    "        return np.where(wtA, np.where(wtB, np.where(wtC, 3, 2), 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afba0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlwaysMeanRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return len(X) * [0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a97f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousBaselocRegressor(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"This baseline regressor should only recieve nos metric as input.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cutoff_a = 80\n",
    "        self.cutoff_b = 275\n",
    "        self.cutoff_c = 500\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        wtA = X[:,0] > self.cutoff_a\n",
    "        wtB = X[:,0] > self.cutoff_b\n",
    "        wtC = X[:,0] > self.cutoff_c\n",
    "        return np.where(wtA, np.where(wtB, np.where(wtC, 2.63, 1.97), 0.99), 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0852b95",
   "metadata": {},
   "source": [
    "## Processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "505f9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricType(Enum):\n",
    "    ALL = \"all\"\n",
    "    LOC = \"loc\"\n",
    "    CGC = \"cgc\"\n",
    "\n",
    "class FoldType(Enum):\n",
    "    K_FOLD = \"k-fold\"\n",
    "    PROJECT_WISE = \"project-wise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3234ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_columns(metric_type):\n",
    "    \n",
    "    if (metric_type == MetricType.ALL):\n",
    "        columns = METRIC_COLUMNS\n",
    "    elif (metric_type == MetricType.LOC):\n",
    "        columns = METRIC_COLUMNS_LOC\n",
    "    elif (metric_type == MetricType.CGC):\n",
    "        columns = METRIC_COLUMNS_CGC\n",
    "    \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f96e8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_metrics(df, metric_type=MetricType.ALL):\n",
    "    \"Sort metrics by descending mutual information with the target.\"\n",
    "    \n",
    "    mi = []\n",
    "    discrete_features = [False if (m == 'nos_am' or m == 'non_am') else True for m in METRIC_COLUMNS]\n",
    "    for seed in SEEDS:\n",
    "        mi.append(mutual_info_classif(df[METRIC_COLUMNS], df['target'], random_state=seed,\n",
    "                                      discrete_features=discrete_features))\n",
    "\n",
    "    mi_means = np.mean(mi, axis=0)\n",
    "    mi_stds = np.std(mi, axis=0)\n",
    "\n",
    "    sorted_metrics = pd.DataFrame({'mi': mi_means, 'std': mi_stds}, index=METRIC_COLUMNS)\n",
    "    sorted_metrics = sorted_metrics.sort_values(by='mi', ascending=False)\n",
    "    columns = get_metrics_columns(metric_type)\n",
    "    return sorted_metrics[sorted_metrics.index.isin(columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50ab49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_metrics_probabilities(df, metric_type=MetricType.ALL):\n",
    "    \"Sort metrics by descending mutual information with the target.\"\n",
    "    \n",
    "    mi = []\n",
    "    discrete_features = [False if (m == 'nos_am' or m == 'non_am') else True for m in METRIC_COLUMNS]\n",
    "    target_ = np.array(df['target'].tolist())\n",
    "    for seed in SEEDS:\n",
    "        mi.append(mutual_info_regression(df[METRIC_COLUMNS], target_[:,0], random_state=seed,\n",
    "                                         discrete_features=discrete_features))\n",
    "        mi.append(mutual_info_regression(df[METRIC_COLUMNS], target_[:,1], random_state=seed,\n",
    "                                         discrete_features=discrete_features))\n",
    "        mi.append(mutual_info_regression(df[METRIC_COLUMNS], target_[:,2], random_state=seed,\n",
    "                                         discrete_features=discrete_features))\n",
    "        mi.append(mutual_info_regression(df[METRIC_COLUMNS], target_[:,3], random_state=seed,\n",
    "                                         discrete_features=discrete_features))\n",
    "\n",
    "    mi_means = np.mean(mi, axis=0)\n",
    "    mi_stds = np.std(mi, axis=0)\n",
    "\n",
    "    sorted_metrics = pd.DataFrame({'mi': mi_means, 'std': mi_stds}, index=METRIC_COLUMNS)\n",
    "    sorted_metrics = sorted_metrics.sort_values(by='mi', ascending=False)\n",
    "    columns = get_metrics_columns(metric_type)\n",
    "    return sorted_metrics[sorted_metrics.index.isin(columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b0f6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_metrics_continuous(df, metric_type=MetricType.ALL):\n",
    "    \"Sort metrics by descending mutual information with the target.\"\n",
    "    \n",
    "    mi = []\n",
    "    discrete_features = [False if (m == 'nos_am' or m == 'non_am') else True for m in METRIC_COLUMNS]\n",
    "    for seed in SEEDS:\n",
    "        mi.append(mutual_info_regression(df[METRIC_COLUMNS], df['target'], random_state=seed,\n",
    "                                         discrete_features=discrete_features))\n",
    "\n",
    "    mi_means = np.mean(mi, axis=0)\n",
    "    mi_stds = np.std(mi, axis=0)\n",
    "\n",
    "    sorted_metrics = pd.DataFrame({'mi': mi_means, 'std': mi_stds}, index=METRIC_COLUMNS)\n",
    "    sorted_metrics = sorted_metrics.sort_values(by='mi', ascending=False)\n",
    "    columns = get_metrics_columns(metric_type)\n",
    "    return sorted_metrics[sorted_metrics.index.isin(columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b1d2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_dict(parameters):\n",
    "    \"\"\"Parse the parameters as a Python dictionary.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        parameters = ast.literal_eval(parameters)\n",
    "    except:\n",
    "        raise ValueError(\"Parameters should be valid Python code representing a dictionary\")\n",
    "    if not isinstance(parameters, dict):\n",
    "        raise ValueError(\"Parameters should be a Python dictionary\")\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aad437a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(name, parameters, preprocessing, oversampling, seed):\n",
    "    \"\"\"Get a pipeline instanciated with the given parameters.\"\"\"\n",
    "    \n",
    "    parameters = as_dict(parameters)\n",
    "    estimator = get_estimator(name, parameters, seed)\n",
    "        \n",
    "    if oversampling:\n",
    "        oversampler = ('smote_variants', 'MulticlassOversampling',\n",
    "                       {'oversampler': 'kmeans_SMOTE', 'oversampler_params': {'n_clusters': 2, 'random_state': seed}})\n",
    "        estimator_params = (type(estimator).__module__, type(estimator).__name__, estimator.get_params())\n",
    "        estimator = OversamplingClassifier(oversampler, estimator_params)\n",
    "    \n",
    "    if preprocessing == 'Standardization':\n",
    "        pipeline = [StandardScaler(), estimator]\n",
    "    elif preprocessing == 'Normalization':\n",
    "        pipeline = [MinMaxScaler(), estimator]\n",
    "    else:\n",
    "        pipeline = [estimator]\n",
    "    \n",
    "    return make_pipeline(*pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c5251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_iterator(fold_type, seed):\n",
    "    \"\"\"Get the cross-validation iterator corresponding to the fold-type.\"\"\"\n",
    "    \n",
    "    if (fold_type == FoldType.PROJECT_WISE):\n",
    "        cv = LeaveOneGroupOut()\n",
    "    elif (fold_type == FoldType.K_FOLD):\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        raise ValueError(\"No fold type chosen.\")\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90e0ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row, df, sorted_metrics, scoring, fold_type=FoldType.PROJECT_WISE):\n",
    "    \"\"\"Fit the estimator definied by row\n",
    "    by project-wise cross-validation on all seeds \n",
    "    and return the scores dict defined by scoring.\"\"\"\n",
    "\n",
    "    debug_log(\"called!\")\n",
    "\n",
    "    \n",
    "    scores = {key: [] for key in scoring.keys()}\n",
    "    \n",
    "    X = df[sorted_metrics.index[:row.metrics]].values\n",
    "    y = df['target'].values\n",
    "    groups = df.projectname.values\n",
    "    y_fold = df['fold'].values\n",
    "    \n",
    "    if (\"Baseloc\" in row.estimator):\n",
    "        X = df[['nos']].values\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        clf = get_pipeline(row.estimator, row.parameters, row.preprocessing, row.oversampling, seed)\n",
    "        cv = get_cv_iterator(fold_type, seed)\n",
    "        cv_scores = cross_validate(clf, X, y, cv=cv.split(X, y_fold, groups), scoring=scoring)\n",
    "        for key in scoring.keys():\n",
    "            scores[key].extend(cv_scores.get(\"test_\" + key))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83630e25-4d19-4b7c-a8d1-c614095e6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_log(message):\n",
    "    with open(\"debug_log.txt\", \"a\") as file:\n",
    "        file.write(message + \"\\n\")\n",
    "\n",
    "# Use debug_log(\"Your message\") instead of print(\"Your message\") inside process_with_probs_and_save\n",
    "debug_log(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b52c85c5-3127-4b9c-9134-0aa10020eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_log(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdc34c82-6293-472b-9bbc-252e2128c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_with_probs_and_save(row, df, sorted_metrics, fold_type, output_dir='output', scoring=None):\n",
    "    \"\"\"Fit the estimator defined by row by project-wise cross-validation on all seeds,\n",
    "    and save the prediction probabilities to a uniquely named CSV file.\"\"\"\n",
    "    debug_log(\"called!\")\n",
    "    \n",
    "    # Ensure scoring is defined here if not passed as a parameter\n",
    "    if scoring is None:\n",
    "        scoring = {'f-score': 'f1', 'auc': 'roc_auc', 'recall': 'recall', 'precision': 'precision'}\n",
    "        \n",
    "    scores = {key: [] for key in scoring.keys()}\n",
    "    probabilities = []\n",
    "    \n",
    "    X = df[sorted_metrics.index[:row.metrics]].values\n",
    "    y = df['target'].values\n",
    "    groups = df['projectname'].values  # Assuming projectname is the correct column name\n",
    "    y_fold = df['fold'].values\n",
    "    \n",
    "    if \"Baseloc\" in row['estimator']:\n",
    "        X = df[['nos']].values\n",
    "    \n",
    "    # Prepare unique filename for the output CSV\n",
    "    model_identifier = f\"{row['estimator']}_params_{row['parameters']}\".replace(\" \", \"_\").replace(\",\", \"\").replace(\":\", \"_\")\n",
    "    output_csv = f\"{output_dir}/{model_identifier}.csv\"\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        clf = get_pipeline(row['estimator'], row['parameters'], row['preprocessing'], row['oversampling'], seed)\n",
    "        cv = get_cv_iterator(fold_type, seed)\n",
    "        \n",
    "        # Here, we use cross_val_predict to get the prediction probabilities for each fold\n",
    "        y_probas = cross_val_predict(clf, X, y, cv=cv.split(X, y_fold, groups), method='predict_proba')\n",
    "        \n",
    "        probabilities.extend(y_probas[:, 1])  # Assuming the positive class is at index 1\n",
    "\n",
    "    # After collecting all probabilities, save them to a CSV file\n",
    "    probabilities_df = pd.DataFrame(probabilities, columns=['PredictionProbability'])\n",
    "    probabilities_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Check if the file has been successfully saved\n",
    "    if os.path.exists(output_csv):\n",
    "        print(f\"File '{output_csv}' saved successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to save file '{output_csv}'.\")\n",
    "    \n",
    "    return scores, output_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "343bd25a-d274-495e-8b19-5495a10f5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mrksbrg/Documents/Code/maintainability-dataset-analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86dd544",
   "metadata": {},
   "source": [
    "## Output methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83ec5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(values):\n",
    "    return round(np.mean(values), 4)\n",
    "    \n",
    "def std(values):\n",
    "    return round(np.std(values), 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
